---
title: "NYSAT"
author: "EKLAR"
date: 'null'
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Links to the Datasource

+ NYC sat scores for 2012-https://data.cityofnewyork.us/Education/2012-SAT-Results/f9bf-2cp4

+ school accountability- https://data.cityofnewyork.us/Education/2006-2012-School-Demographics-and-Accountability-S/ihfw-zy9j

+ NYC general education survey-https://data.cityofnewyork.us/Education/2012-NYC-General-Education-School-Survey/xiyj-m4sj


```{r,include=FALSE}
#Loading Required Library's
# install these library's if they are missing in your local machine
#with install.packages()
#install.packages('here')
#install.packages('data.table')
#install.packages('dplyr')
#install.packages("corrplot", dependencies = TRUE)
#install.packages("ztable")
#install.packages("moments")

library(here) 
library(data.table)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(corrplot)
library(ztable)
library(moments)
library(readxl)
library(openxlsx)
```

```{r, reading the data,include=FALSE}
sat_scores<-
  fread(here("RawData","2012_SAT_Results.csv"))
school_demographic<-
  fread(here("RawData","2006_-_2012_School_Demographics_and_Accountability_Snapshot.csv"))
school_survey<-
  fread(here("RawData","2012_NYC_General_Education_School_Survey.csv"))
```

```{r,include=FALSE}
# Joining the three datasets
school_demographic2012<-school_demographic%>%filter(schoolyear=="20112012")
joined_satanddemographic<-left_join(sat_scores,school_demographic2012,"DBN")
all_joined<-left_join(joined_satanddemographic,school_survey,"DBN")

df<- 
  all_joined%>%select(DBN,
                      `SCHOOL NAME`,
                      `Num of SAT Test Takers`,
                      'School Type',
                      'total_enrollment',
                      `SAT Critical Reading Avg. Score`,
                      `SAT Math Avg. Score`,
                      `SAT Writing Avg. Score`,
                      male_per,
                      female_per,
                      black_per,
                      white_per,
                      hispanic_per,
                      asian_per,
                      ell_percent,
                      frl_percent) 

df[] <- lapply(df, function(x) as.character(gsub("s", NA, x))) #replacing "s" with NA's

df[3:length(df)]<-lapply(df[5:length(df)],function(x) as.numeric(x)) # converting columns to 
                                                                      # numeric



df<-na.omit(df)

```

```{r, finding averages by school categories,include=FALSE}
 # Converting columns to numeric
str(df)
 Readingaverage =  tapply(df$`SAT Critical Reading Avg. Score`,df$`School Type`, mean)
 Mathaverage =  tapply(df$`SAT Math Avg. Score`,df$`School Type`, mean)
 Writingaverage =  tapply(df$`SAT Writing Avg. Score`,df$`School Type`, mean)
 ReadingSD =  tapply(df$`SAT Critical Reading Avg. Score`,df$`School Type`, sd)
 MathSD =  tapply(df$`SAT Math Avg. Score`,df$`School Type`, sd)
 WritingSD =  tapply(df$`SAT Writing Avg. Score`,df$`School Type`, sd)
 
 
 SATtesttaker =  tapply(df$`Num of SAT Test Takers`,df$`School Type`, sum)
 TotalEnrollment =  tapply(df$total_enrollment,df$`School Type`, sum)
Read =c(Readingaverage)
Math =c(Mathaverage)
Writing = c(Writingaverage)
ReadSD = c(ReadingSD)
MathsSD = c(MathSD) 
WritSD =c(WritingSD)
Taker= c(SATtesttaker)
Enrol= c (TotalEnrollment)
rbind(Read, Math, Writing, ReadSD, MathsSD, WritSD, Taker, Enrol)
```




```{r}
#include summary of dataset 
summary(df)   
```

#Explorotary data analysis

```{r, explore data}
# How SAT is scored-(Ehtesham)

# check the code in the Joining the three datasets section to make sure that 
 # we have the nessesary variables + any accuracy issues (Ehtesham)

# add the survey response columns from all_joined to df dataframe (laknath)

# make characrter columns numeric that have SAT scores and percentage (Abinav)

# Based on the real data deternime how we combine scores/or whether to keep seperate (Abhinav)
  # should include histogram also boxplot (abhinav)

# see if there is difference in aveage scores between just high scool vs those other types
  # see if tere is difference between male and female (Ehtesham)


# correlation plot (multi coleniarity) -Raj
    # also include the numbers -Raj

# plot histogram of (distribution) of SAT scores -Raj/Kushboo

```  




# Determine if there is a relationship between enrollment and SAT scores-scatterplot (Laknath)
```{r}

pl_math<-ggplot(data = df)+
  geom_point(mapping = aes(x = total_enrollment,y = `SAT Math Avg. Score`),
             color="red",position = "jitter")

pl_reading<-ggplot(data = df)+
  geom_point(mapping = aes(x = total_enrollment,y = `SAT Critical Reading Avg. Score`),
             color="green",position = "jitter")

pl_writing<-ggplot(data = df)+
  geom_point(mapping = aes(x = total_enrollment,y = `SAT Writing Avg. Score`),
             color="orange",position = "jitter")

ggarrange(pl_math,pl_reading,pl_writing)


```
It looks like there is a positve linear association between enrollment and SAT reading scores

```{r, RAJ}

#Error check
df$totgen = df$male_per + df$female_per
df$totdiv = df$black_per + df$white_per + df$hispanic_per + df$asian_per

#Simpson Diversity index
df$div = 1 - (((df$black_per*(df$black_per-1))+(df$white_per*(df$white_per-1))+(df$hispanic_per*(df$hispanic_per-1))+(df$asian_per*(df$asian_per-1)))/9900)

# Missing data check
#summary(dfr)
#apply(dfr,2,function(x) sum(is.na(x)))
#apply(dfr,2,function(x) sum(is.na(x))*100/nrow(dfr)) #percentage of NAs

percentmiss = function(x){sum(is.na(x))/length(x)*100} #percent miss row
missing = apply(df,1,percentmiss)
table(missing)
replace = subset(df, missing <= 5)
missing1 = apply(replace,1,percentmiss)
table(missing1)
dont = subset(df, missing > 5)
missing2 = apply(dont,1,percentmiss)
table(missing2)
#apply(replace,2,percentmiss) #missing in column


# Outlier check
mah = mahalanobis(replace[,-c(1,2,16,17,18)],
                    colMeans(replace[,-c(1,2,16,17,18)], na.rm=TRUE),
                    cov(replace[,-c(1,2,16,17,18)], use ="pairwise.complete.obs")
                    )    # This piece of code doesn't seem to work
#mah
cutoff = qchisq(1-.001,ncol(replace))
#print(cutoff)
summary(mah < cutoff)
noout = subset(replace, mah < cutoff) #Eliminate outliers
#str(noout)
```
# Correlation
```{r results='asis'}
# Additivity check
corrplot(cor(noout[,-c(1,2,16,17)]))
cormat = cor(noout[,-c(1,2,16,17)]) #Correlation quantified

cormat %>%
  as.data.frame() %>%
  ztable() %>% 
  makeHeatmap(mycolor = gradientColor(low="red",mid="white",high="blue")) %>%
  print(caption="Correlation Heatmap")
```

```{r, Norm}
#Normality check
plot.new()
par(mfrow=c(3, 3)); hist(noout$`SAT Critical Reading Avg. Score`, breaks=15, main = "SAT Reading", xlab=NA, ylab=NA); hist(noout$`SAT Math Avg. Score`, breaks=15, main = "SAT Math", xlab=NA, ylab=NA); hist(noout$`SAT Writing Avg. Score`, breaks=15, main = "SAT Writing", xlab=NA, ylab=NA); hist(noout$ell_percent, breaks=15, main = "ELL", xlab=NA, ylab=NA); hist(noout$frl_percent, breaks=15, main = "FRL", xlab=NA, ylab=NA); hist(noout$female_per, breaks=15, main = "Female %", xlab=NA, ylab=NA); hist(noout$white_per, breaks=15, main = "White %", xlab=NA, ylab=NA); hist(noout$black_per, breaks=15, main = "Black %", xlab=NA, ylab=NA); hist(noout$asian_per, breaks=15, main = "Asian %", xlab=NA, ylab=NA)

#apply(noout[,-c(1,2,16,17)], 2, skewness, na.rm =TRUE)
#apply(noout[,-c(1,2,16,17)], 2, kurtosis, na.rm =TRUE)

hist(noout$div, breaks=25, main = "Diversity", xlab=NA, ylab=NA)

par(mfrow=c(2, 2)); plot(noout$white_per, noout$asian_per); plot(noout$white_per, noout$black_per); plot(noout$hispanic_per, noout$black_per); plot(noout$hispanic_per, noout$asian_per)

plot(noout$white_per, noout$`SAT Writing Avg. Score`)

```



